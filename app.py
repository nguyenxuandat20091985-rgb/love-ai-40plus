"""
H·ªÜ TH·ªêNG AI NH·∫ÆN TIN TR∆Ø·ªûNG TH√ÄNH CHO NAM 40+
"""
import re
import random
import json
import time
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, asdict
import hashlib
from enum import Enum

class RelationshipStage(Enum):
    """Giai ƒëo·∫°n quan h·ªá"""
    NEW = "new"           # M·ªõi quen, ƒëang t√°n
    DATING = "dating"     # ƒêang h·∫πn h√≤
    SERIOUS = "serious"   # Nghi√™m t√∫c
    COMMITTED = "committed" # G·∫Øn b√≥
    
class ResponseStrategy(Enum):
    """Chi·∫øn l∆∞·ª£c ph·∫£n h·ªìi"""
    MAINTAIN_VALUE = "giu_gia_tri"
    MODERATE_CARE = "quan_tam_vua_du"
    GIVE_SPACE = "cho_khong_gian"
    EMOTIONAL_CONNECT = "ket_noi_cam_xuc"
    PLAYFUL_TEASE = "tinh_te_dua"
    DEEP_SHARE = "chia_se_sau"

@dataclass
class MessageAnalysis:
    """K·∫øt qu·∫£ ph√¢n t√≠ch tin nh·∫Øn"""
    original_text: str
    detected_context: str
    emotion_level: str  # 'nh·∫π', 'v·ª´a', 's√¢u'
    urgency: float  # 0-1
    emotional_tone: Dict[str, float]  # positive, negative, neutral
    keywords: List[str]
    implied_needs: List[str]
    requires_follow_up: bool = False
    
class MatureMessagingAI:
    """H·ªá th·ªëng AI nh·∫Øn tin tr∆∞·ªüng th√†nh"""
    
    def __init__(self, data_path: str = "scenario_data.json"):
        self.data_path = data_path
        self.context_groups = self._load_scenario_data()
        self.conversation_history = []
        self.relationship_stage = RelationshipStage.DATING
        self.user_profile = {
            "gender": "male",
            "age_group": "40+",
            "communication_style": "mature_refined"
        }
        
        # T·ª´ kh√≥a c·∫£m x√∫c ƒë·ªÉ nh·∫≠n di·ªán
        self.emotion_keywords = {
            "bu·ªìn": ["bu·ªìn", "ch√°n", "t·ªá", "m·ªát", "th·∫•t v·ªçng"],
            "vui": ["vui", "t·ªët", "tuy·ªát", "h·∫°nh ph√∫c", "th√≠ch"],
            "gi·∫≠n": ["gi·∫≠n", "t·ª©c", "b·ª±c", "kh√≥ ch·ªãu", "phi·ªÅn"],
            "lo": ["lo", "s·ª£", "bƒÉn khoƒÉn", "b·∫•t an", "cƒÉng th·∫≥ng"],
            "trung_l·∫≠p": ["·ªïn", "b√¨nh th∆∞·ªùng", "t·∫°m ƒë∆∞·ª£c", "c≈©ng ƒë∆∞·ª£c"]
        }
        
        # Mapping ng·ªØ c·∫£nh v·ªõi t·ª´ kh√≥a
        self.context_patterns = self._build_context_patterns()
        
    def _load_scenario_data(self) -> Dict:
        """T·∫£i d·ªØ li·ªáu t√¨nh hu·ªëng t·ª´ file JSON"""
        try:
            with open(self.data_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            # Tr·∫£ v·ªÅ d·ªØ li·ªáu m·∫´u n·∫øu file kh√¥ng t·ªìn t·∫°i
            return self._create_sample_data()
    
    def _create_sample_data(self) -> Dict:
        """T·∫°o d·ªØ li·ªáu m·∫´u v·ªõi √≠t nh·∫•t 25 nh√≥m ng·ªØ c·∫£nh"""
        sample_data = {
            "context_groups": [
                {
                    "name": "h·ªèi thƒÉm",
                    "keywords": ["kh·ªèe kh√¥ng", "th·∫ø n√†o", "c√≥ ·ªïn kh√¥ng", "d·∫°o n√†y", "sao r·ªìi"],
                    "typical_scenarios": ["H·ªèi thƒÉm th√¥ng th∆∞·ªùng", "H·ªèi thƒÉm sau th·ªùi gian kh√¥ng li√™n l·∫°c"],
                    "response_strategy": "quan_tam_vua_du",
                    "emotion_levels": {
                        "nh·∫π": {
                            "variants": [
                                {"text": "Anh ·ªïn. Em th·∫ø n√†o?", "delay_range": [2, 4], "follow_up": 0.2},
                                {"text": "V·∫´n b√¨nh th∆∞·ªùng. C√≤n em?", "delay_range": [1, 3], "follow_up": 0.1},
                                {"text": "·ªîn c·∫£. Em d·∫°o n√†y sao?", "delay_range": [2, 5], "follow_up": 0.3}
                            ]
                        },
                        "v·ª´a": {
                            "variants": [
                                {"text": "C·∫£m ∆°n em quan t√¢m. Anh v·∫´n ·ªïn, d√π h∆°i b·∫≠n. Em th·∫ø n√†o?", "delay_range": [3, 6], "follow_up": 0.4},
                                {"text": "C≈©ng t·∫°m ·ªïn. C√≥ g√¨ m·ªõi kh√¥ng em?", "delay_range": [2, 4], "follow_up": 0.3}
                            ]
                        },
                        "s√¢u": {
                            "variants": [
                                {"text": "C·∫£m ∆°n em nh·ªõ h·ªèi. C√≥ ƒë√¥i ch√∫t m·ªát m·ªèi nh∆∞ng ·ªïn. Em c√≥ g√¨ mu·ªën chia s·∫ª kh√¥ng?", "delay_range": [4, 8], "follow_up": 0.6},
                                {"text": "G·∫ßn ƒë√¢y c√≥ nhi·ªÅu chuy·ªán, nh∆∞ng anh xoay x·ªü ƒë∆∞·ª£c. Nghe gi·ªçng em c√≥ v·∫ª lo l·∫Øng g√¨ ƒë√≥?", "delay_range": [5, 10], "follow_up": 0.5}
                            ]
                        }
                    }
                },
                {
                    "name": "m·ªát",
                    "keywords": ["m·ªát", "m·ªèi", "ki·ªát s·ª©c", "ƒëu·ªëi", "h·∫øt nƒÉng l∆∞·ª£ng"],
                    "typical_scenarios": ["M·ªát sau l√†m vi·ªác", "M·ªát v√¨ c√¥ng vi·ªác", "M·ªát tinh th·∫ßn"],
                    "response_strategy": "quan_tam_vua_du",
                    "emotion_levels": {
                        "nh·∫π": {
                            "variants": [
                                {"text": "Ngh·ªâ ng∆°i ch√∫t ƒëi em.", "delay_range": [2, 4], "follow_up": 0.3},
                                {"text": "U·ªëng n∆∞·ªõc ·∫•m v√†o. Anh c≈©ng hay th·∫ø.", "delay_range": [3, 5], "follow_up": 0.2}
                            ]
                        },
                        "v·ª´a": {
                            "variants": [
                                {"text": "C√¥ng vi·ªác nhi·ªÅu qu√° h·∫£? Ngh·ªâ ng∆°i ƒëi, s·ª©c kh·ªèe quan tr·ªçng l·∫Øm.", "delay_range": [3, 6], "follow_up": 0.4},
                                {"text": "Anh hi·ªÉu c·∫£m gi√°c ƒë√≥. C·ªë g·∫Øng s·∫Øp x·∫øp l·∫°i c√¥ng vi·ªác xem sao.", "delay_range": [4, 7], "follow_up": 0.5}
                            ]
                        },
                        "s√¢u": {
                            "variants": [
                                {"text": "Nghe em n√≥i m√† anh th·∫•y lo. M·ªát qu√° th√¨ ngh·ªâ ng∆°i ƒëi, ƒë·ª´ng c·ªë qu√°. C√≥ c·∫ßn anh gi√∫p g√¨ kh√¥ng?", "delay_range": [5, 10], "follow_up": 0.7},
                                {"text": "Anh t·ª´ng tr·∫£i qua r·ªìi. ƒê√¥i khi m·ªát m·ªèi l√† d·∫•u hi·ªáu c·∫ßn thay ƒë·ªïi. Mu·ªën n√≥i chuy·ªán kh√¥ng em?", "delay_range": [6, 12], "follow_up": 0.8}
                            ]
                        }
                    }
                },
                # Th√™m 23+ nh√≥m kh√°c t∆∞∆°ng t·ª±...
                {
                    "name": "stress",
                    "keywords": ["stress", "cƒÉng th·∫≥ng", "√°p l·ª±c", "ƒë·∫ßu √≥c cƒÉng", "qu√° t·∫£i"]
                },
                {
                    "name": "l·∫°nh",
                    "keywords": ["l·∫°nh", "tr·ªùi l·∫°nh", "r√©t", "·ªõn l·∫°nh", "l·∫°nh bu·ªët"]
                },
                {
                    "name": "th·ª≠ l√≤ng",
                    "keywords": ["c√≥ nh·ªõ kh√¥ng", "c√≥ y√™u kh√¥ng", "c√≥ th∆∞∆°ng kh√¥ng", "th·ª≠ xem", "ki·ªÉm tra"]
                },
                {
                    "name": "gi·∫≠n nh·∫π",
                    "keywords": ["h·ªùn", "gi·∫≠n", "kh√¥ng th√®m n√≥i", "kh√¥ng quan t√¢m", "m·∫∑c k·ªá"]
                },
                {
                    "name": "im l·∫∑ng",
                    "keywords": ["...", "im l·∫∑ng", "kh√¥ng n√≥i g√¨", "th√¥i", "k·ªá"]
                }
            ]
        }
        return sample_data
    
    def _build_context_patterns(self) -> Dict:
        """X√¢y d·ª±ng patterns nh·∫≠n di·ªán ng·ªØ c·∫£nh"""
        patterns = {}
        for group in self.context_groups.get("context_groups", []):
            patterns[group["name"]] = {
                "keywords": group.get("keywords", []),
                "regex_patterns": [re.compile(rf'\b{kw}\b', re.IGNORECASE) for kw in group["keywords"]]
            }
        return patterns
    
    def analyze_message(self, message: str) -> MessageAnalysis:
        """Ph√¢n t√≠ch tin nh·∫Øn ƒë·∫øn"""
        message_lower = message.lower()
        
        # Nh·∫≠n di·ªán ng·ªØ c·∫£nh
        detected_context = self._detect_context(message_lower)
        
        # Ph√¢n t√≠ch c·∫£m x√∫c
        emotion_level, emotional_tone = self._analyze_emotion(message_lower)
        
        # Ph√¢n t√≠ch t·ª´ kh√≥a
        keywords = self._extract_keywords(message_lower)
        
        # ƒê√°nh gi√° ƒë·ªô kh·∫©n c·∫•p
        urgency = self._assess_urgency(message_lower, emotional_tone)
        
        # X√°c ƒë·ªãnh nhu c·∫ßu ·∫©n
        implied_needs = self._identify_implied_needs(message_lower, detected_context)
        
        return MessageAnalysis(
            original_text=message,
            detected_context=detected_context,
            emotion_level=emotion_level,
            urgency=urgency,
            emotional_tone=emotional_tone,
            keywords=keywords,
            implied_needs=implied_needs,
            requires_follow_up=self._should_follow_up(message_lower, emotional_tone)
        )
    
    def _detect_context(self, message: str) -> str:
        """Nh·∫≠n di·ªán ng·ªØ c·∫£nh c·ªßa tin nh·∫Øn"""
        best_match = "unknown"
        highest_score = 0
        
        for context_name, patterns in self.context_patterns.items():
            score = 0
            for keyword in patterns["keywords"]:
                if keyword in message:
                    score += 1
            for pattern in patterns["regex_patterns"]:
                if pattern.search(message):
                    score += 2
            
            if score > highest_score:
                highest_score = score
                best_match = context_name
        
        return best_match if highest_score > 0 else "neutral"
    
    def _analyze_emotion(self, message: str) -> Tuple[str, Dict]:
        """Ph√¢n t√≠ch m·ª©c ƒë·ªô c·∫£m x√∫c"""
        emotion_scores = {
            "positive": 0,
            "negative": 0,
            "neutral": 0,
            "intensity": 0
        }
        
        # ƒê·∫øm t·ª´ kh√≥a c·∫£m x√∫c
        for emotion_type, keywords in self.emotion_keywords.items():
            for keyword in keywords:
                if keyword in message:
                    if emotion_type == "vui":
                        emotion_scores["positive"] += 1
                    elif emotion_type in ["bu·ªìn", "gi·∫≠n", "lo"]:
                        emotion_scores["negative"] += 1
                    else:
                        emotion_scores["neutral"] += 1
        
        # Ph√°t hi·ªán d·∫•u hi·ªáu c·∫£m x√∫c m·∫°nh
        intensity_indicators = ["r·∫•t", "qu√°", "c·ª±c k·ª≥", "v√¥ c√πng", "h∆°i", "kh√°"]
        for indicator in intensity_indicators:
            if indicator in message:
                emotion_scores["intensity"] += 1
        
        # X√°c ƒë·ªãnh m·ª©c ƒë·ªô c·∫£m x√∫c
        total_emotion_words = sum(emotion_scores.values()) - emotion_scores["intensity"]
        
        if total_emotion_words == 0:
            emotion_level = "nh·∫π"
        elif total_emotion_words <= 2:
            emotion_level = "nh·∫π" if emotion_scores["intensity"] < 2 else "v·ª´a"
        else:
            if emotion_scores["intensity"] >= 3:
                emotion_level = "s√¢u"
            elif emotion_scores["intensity"] >= 1:
                emotion_level = "v·ª´a"
            else:
                emotion_level = "nh·∫π"
        
        return emotion_level, emotion_scores
    
    def _extract_keywords(self, message: str) -> List[str]:
        """Tr√≠ch xu·∫•t t·ª´ kh√≥a quan tr·ªçng"""
        # ƒê∆°n gi·∫£n: t√°ch t·ª´ v√† l·ªçc c√°c t·ª´ c√≥ √Ω nghƒ©a
        words = message.split()
        stop_words = ["v√†", "nh∆∞ng", "m√†", "th√¨", "l√†", "c√≥", "kh√¥ng", "r·∫•t", "qu√°"]
        keywords = [word for word in words if len(word) > 2 and word not in stop_words]
        return keywords[:10]  # Gi·ªõi h·∫°n 10 t·ª´ kh√≥a
    
    def _assess_urgency(self, message: str, emotional_tone: Dict) -> float:
        """ƒê√°nh gi√° ƒë·ªô kh·∫©n c·∫•p c·ªßa tin nh·∫Øn"""
        urgency_signals = [
            ("g·∫•p", 0.8), ("ngay", 0.7), ("l·∫≠p t·ª©c", 0.9),
            ("c·ª©u", 1.0), ("gi√∫p", 0.6), ("nguy hi·ªÉm", 0.9),
            ("?", 0.3), ("???", 0.6), ("!", 0.4), ("!!!", 0.7)
        ]
        
        urgency_score = 0
        for signal, weight in urgency_signals:
            if signal in message:
                urgency_score += weight
        
        # C·∫£m x√∫c ti√™u c·ª±c m·∫°nh l√†m tƒÉng ƒë·ªô kh·∫©n
        if emotional_tone["negative"] > 2:
            urgency_score += 0.3
        
        return min(1.0, urgency_score / 5.0)  # Chu·∫©n h√≥a v·ªÅ 0-1
    
    def _identify_implied_needs(self, message: str, context: str) -> List[str]:
        """X√°c ƒë·ªãnh nhu c·∫ßu ·∫©n trong tin nh·∫Øn"""
        needs = []
        
        # Ph√¢n t√≠ch d·ª±a tr√™n ng·ªØ c·∫£nh
        if context in ["m·ªát", "stress"]:
            needs.extend(["comfort", "understanding", "space"])
        elif context in ["bu·ªìn vu v∆°", "c·∫ßn an ·ªßi"]:
            needs.extend(["comfort", "listening", "empathy"])
        elif context in ["th·ª≠ l√≤ng", "gi·∫≠n nh·∫π"]:
            needs.extend(["reassurance", "attention", "validation"])
        elif context in ["mu·ªën g·∫∑p", "ch·ªß ƒë·ªông"]:
            needs.extend(["connection", "meeting", "time"])
        
        # Th√™m nhu c·∫ßu d·ª±a tr√™n t·ª´ kh√≥a
        if "m·ªôt m√¨nh" in message or "·ªü m·ªôt m√¨nh" in message:
            needs.append("space")
        if "n√≥i chuy·ªán" in message or "t√¢m s·ª±" in message:
            needs.append("talking")
        
        return list(set(needs))  # Remove duplicates
    
    def _should_follow_up(self, message: str, emotional_tone: Dict) -> bool:
        """Quy·∫øt ƒë·ªãnh c√≥ c·∫ßn follow-up kh√¥ng"""
        # N·∫øu c√≥ d·∫•u h·ªèi v√† c·∫£m x√∫c m·∫°nh
        if "?" in message and (emotional_tone["positive"] > 1 or emotional_tone["negative"] > 1):
            return True
        
        # N·∫øu c√≥ d·∫•u hi·ªáu c·∫ßn s·ª± ch√∫ √Ω
        attention_seekers = ["ch√°n qu√°", "bu·ªìn qu√°", "kh√¥ng ai n√≥i chuy·ªán", "c√¥ ƒë∆°n"]
        for phrase in attention_seekers:
            if phrase in message:
                return True
        
        return False
    
    def generate_response(self, analysis: MessageAnalysis) -> Dict:
        """T·∫°o c√¢u tr·∫£ l·ªùi ph√π h·ª£p"""
        # L·∫•y nh√≥m ng·ªØ c·∫£nh ph√π h·ª£p
        context_group = None
        for group in self.context_groups.get("context_groups", []):
            if group["name"] == analysis.detected_context:
                context_group = group
                break
        
        if not context_group:
            # Fallback v·ªÅ neutral response
            return self._generate_fallback_response(analysis)
        
        # Ch·ªçn m·ª©c c·∫£m x√∫c ph√π h·ª£p
        emotion_level = analysis.emotion_level
        if emotion_level not in context_group.get("emotion_levels", {}):
            # Fallback v·ªÅ m·ª©c v·ª´a n·∫øu kh√¥ng c√≥ m·ª©c c·ª• th·ªÉ
            emotion_level = "v·ª´a"
        
        # L·∫•y c√°c bi·∫øn th·ªÉ c√≥ th·ªÉ
        variants = context_group["emotion_levels"][emotion_level]["variants"]
        
        # Ch·ªçn ng·∫´u nhi√™n m·ªôt bi·∫øn th·ªÉ
        selected_variant = random.choice(variants)
        
        # T√≠nh ƒë·ªô tr·ªÖ
        delay_range = selected_variant.get("delay_range", [2, 5])
        delay_minutes = random.uniform(delay_range[0], delay_range[1])
        
        # Th√™m t√≠nh ng·∫´u nhi√™n t·ª± nhi√™n
        response = self._add_natural_variations(selected_variant["text"])
        
        # X√¢y d·ª±ng k·∫øt qu·∫£
        result = {
            "response_text": response,
            "delay_minutes": round(delay_minutes, 1),
            "context": analysis.detected_context,
            "emotion_level": emotion_level,
            "strategy": context_group.get("response_strategy", "quan_tam_vua_du"),
            "needs_addressed": analysis.implied_needs,
            "requires_follow_up": selected_variant.get("follow_up", 0.3) > random.random(),
            "timestamp": datetime.now().isoformat()
        }
        
        # L∆∞u v√†o l·ªãch s·ª≠
        self.conversation_history.append({
            "received": analysis.original_text,
            "sent": result,
            "time": datetime.now().isoformat()
        })
        
        return result
    
    def _generate_fallback_response(self, analysis: MessageAnalysis) -> Dict:
        """T·∫°o c√¢u tr·∫£ l·ªùi m·∫∑c ƒë·ªãnh khi kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c ng·ªØ c·∫£nh"""
        fallback_responses = [
            "·ª™, anh nghe ƒë√¢y.",
            "Em n√≥i ƒëi.",
            "C√≥ chuy·ªán g√¨ v·∫≠y?",
            "Anh ƒëang nghe.",
            "Hmm, ti·∫øp ƒëi em."
        ]
        
        # Ch·ªçn d·ª±a tr√™n c·∫£m x√∫c
        if analysis.emotional_tone["negative"] > 1:
            response = "Nghe c√≥ v·∫ª kh√¥ng ·ªïn. Mu·ªën n√≥i g√¨ kh√¥ng em?"
        elif analysis.emotional_tone["positive"] > 1:
            response = "Vui qu√° nh·ªâ. K·ªÉ anh nghe ƒëi."
        else:
            response = random.choice(fallback_responses)
        
        return {
            "response_text": response,
            "delay_minutes": random.uniform(1, 3),
            "context": "neutral",
            "emotion_level": "nh·∫π",
            "strategy": "quan_tam_vua_du",
            "needs_addressed": ["acknowledgment"],
            "requires_follow_up": False,
            "timestamp": datetime.now().isoformat()
        }
    
    def _add_natural_variations(self, text: str) -> str:
        """Th√™m bi·∫øn th·ªÉ t·ª± nhi√™n v√†o c√¢u tr·∫£ l·ªùi"""
        variations = {
            ".": ["", "...", ".."],
            "!": ["", "!", "!!"],
            "?": ["", "?", "??"]
        }
        
        # ƒê√¥i khi th√™m/ b·ªõt d·∫•u c√¢u
        if random.random() < 0.3:
            for original, replacements in variations.items():
                if original in text:
                    if random.random() < 0.5:
                        text = text.replace(original, random.choice(replacements))
        
        # ƒê√¥i khi vi·∫øt t·∫Øt
        abbreviations = {
            "kh√¥ng": "ko",
            "ƒë∆∞·ª£c": "ƒëc",
            "bi·∫øt": "bit",
            "g√¨": "j"
        }
        
        if random.random() < 0.2:  # 20% c∆° h·ªôi vi·∫øt t·∫Øt
            for full, short in abbreviations.items():
                if full in text and random.random() < 0.5:
                    text = text.replace(full, short)
        
        # Th√™m emoji nh·∫π nh√†ng (r·∫•t √≠t)
        emojis = ["", "", "‚òï", ""]
        if random.random() < 0.1:  # Ch·ªâ 10% c∆° h·ªôi d√πng emoji
            text += " " + random.choice(emojis)
        
        return text
    
    def auto_respond(self, message: str) -> Dict:
        """T·ª± ƒë·ªông ph·∫£n h·ªìi t·ª´ ƒë·∫ßu ƒë·∫øn cu·ªëi"""
        # Ph√¢n t√≠ch tin nh·∫Øn
        analysis = self.analyze_message(message)
        
        # T·∫°o ph·∫£n h·ªìi
        response = self.generate_response(analysis)
        
        # Th√™m metadata
        response["analysis"] = {
            "detected_context": analysis.detected_context,
            "emotion_level": analysis.emotion_level,
            "urgency": analysis.urgency,
            "keywords": analysis.keywords[:5]
        }
        
        return response

# ==================== EXTENSION FOR ANDROID ====================

class AndroidAutoMessaging:
    """Extension cho t√≠ch h·ª£p Android"""
    
    def __init__(self, ai_engine: MatureMessagingAI):
        self.ai = ai_engine
        self.message_queue = []
        self.is_active = False
        
    def process_incoming_message(self, contact_name: str, message: str, timestamp: str) -> Dict:
        """X·ª≠ l√Ω tin nh·∫Øn ƒë·∫øn t·ª´ Android"""
        # Ph√¢n t√≠ch v√† t·∫°o ph·∫£n h·ªìi
        response_data = self.ai.auto_respond(message)
        
        # Th√™m th√¥ng tin ng∆∞·ªùi g·ª≠i
        response_data["contact"] = contact_name
        response_data["received_time"] = timestamp
        
        # X·∫øp h√†ng ƒë·ª£i ƒë·ªÉ g·ª≠i
        self.message_queue.append(response_data)
        
        return response_data
    
    def get_next_message_to_send(self) -> Optional[Dict]:
        """L·∫•y tin nh·∫Øn ti·∫øp theo c·∫ßn g·ª≠i"""
        if not self.message_queue:
            return None
            
        # Ki·ªÉm tra xem ƒë√£ ƒë·∫øn l√∫c g·ª≠i ch∆∞a
        current_time = time.time()
        for i, msg in enumerate(self.message_queue):
            # Ki·ªÉm tra delay
            if current_time >= msg.get("scheduled_time", 0):
                return self.message_queue.pop(i)
        
        return None
    
    def schedule_messages(self):
        """L√™n l·ªãch g·ª≠i tin nh·∫Øn"""
        current_time = time.time()
        for msg in self.message_queue:
            if "scheduled_time" not in msg:
                # T√≠nh th·ªùi gian g·ª≠i d·ª±a tr√™n delay
                delay_seconds = msg["delay_minutes"] * 60
                msg["scheduled_time"] = current_time + delay_seconds
                
    def auto_pipeline(self, incoming_messages: List[Dict]) -> List[Dict]:
        """Ch·∫°y pipeline t·ª± ƒë·ªông ho√†n to√†n"""
        responses = []
        
        for msg_data in incoming_messages:
            # X·ª≠ l√Ω m·ªói tin nh·∫Øn
            response = self.process_incoming_message(
                msg_data.get("contact", "Unknown"),
                msg_data.get("message", ""),
                msg_data.get("timestamp", "")
            )
            
            responses.append(response)
        
        # L√™n l·ªãch g·ª≠i
        self.schedule_messages()
        
        return responses

# ==================== WEB INTERFACE (Streamlit) ====================

import streamlit as st

def create_web_interface():
    """Giao di·ªán web d√πng Streamlit"""
    st.set_page_config(page_title="AI Nh·∫Øn Tin Tr∆∞·ªüng Th√†nh", layout="wide")
    
    st.title("ü§µ AI Nh·∫Øn Tin Tr∆∞·ªüng Th√†nh (Nam 40+)")
    st.markdown("---")
    
    # Kh·ªüi t·∫°o AI engine
    if "ai_engine" not in st.session_state:
        st.session_state.ai_engine = MatureMessagingAI()
        st.session_state.conversation = []
    
    # Sidebar c√†i ƒë·∫∑t
    with st.sidebar:
        st.header("‚öôÔ∏è C√†i ƒë·∫∑t")
        relationship_stage = st.selectbox(
            "Giai ƒëo·∫°n quan h·ªá",
            ["M·ªõi quen", "ƒêang h·∫πn h√≤", "Nghi√™m t√∫c", "G·∫Øn b√≥"]
        )
        
        response_style = st.select_slider(
            "M·ª©c ƒë·ªô th√¢n m·∫≠t",
            options=["X√£ giao", "Th√¢n thi·∫øt", "Th√¢n m·∫≠t"]
        )
        
        auto_delay = st.checkbox("T·ª± ƒë·ªông delay", value=True)
        
        if st.button("L√†m m·ªõi h·ªôi tho·∫°i"):
            st.session_state.conversation = []
    
    # Main chat interface
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("üí¨ H·ªôi tho·∫°i")
        
        # Hi·ªÉn th·ªã l·ªãch s·ª≠ h·ªôi tho·∫°i
        chat_container = st.container()
        with chat_container:
            for msg in st.session_state.conversation:
                if msg["type"] == "received":
                    st.markdown(f"""
                    <div style='background-color: #f0f2f6; padding: 10px; border-radius: 10px; margin: 5px;'>
                    <strong>H·ªç:</strong> {msg["text"]}
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    st.markdown(f"""
                    <div style='background-color: #d1ecf1; padding: 10px; border-radius: 10px; margin: 5px;'>
                    <strong>AI:</strong> {msg["text"]}<br>
                    <small>Delay: {msg.get("delay", 0)} ph√∫t | Ng·ªØ c·∫£nh: {msg.get("context", "")}</small>
                    </div>
                    """, unsafe_allow_html=True)
        
        # Nh·∫≠p tin nh·∫Øn m·ªõi
        new_message = st.text_area("Tin nh·∫Øn t·ª´ ƒë·ªëi ph∆∞∆°ng:", height=100)
        
        col_btn1, col_btn2 = st.columns(2)
        with col_btn1:
            if st.button("Ph√¢n t√≠ch & Tr·∫£ l·ªùi", type="primary"):
                if new_message:
                    # Ph√¢n t√≠ch
                    analysis = st.session_state.ai_engine.analyze_message(new_message)
                    
                    # Th√™m v√†o h·ªôi tho·∫°i (tin nh·∫≠n)
                    st.session_state.conversation.append({
                        "type": "received",
                        "text": new_message,
                        "time": datetime.now().strftime("%H:%M")
                    })
                    
                    # T·∫°o ph·∫£n h·ªìi
                    response = st.session_state.ai_engine.generate_response(analysis)
                    
                    # Th√™m v√†o h·ªôi tho·∫°i (tin g·ª≠i)
                    st.session_state.conversation.append({
                        "type": "sent",
                        "text": response["response_text"],
                        "delay": response["delay_minutes"],
                        "context": response["context"],
                        "time": datetime.now().strftime("%H:%M")
                    })
                    
                    st.rerun()
        
        with col_btn2:
            if st.button("X√≥a h·ªôi tho·∫°i"):
                st.session_state.conversation = []
                st.rerun()
    
    with col2:
        st.subheader("üîç Ph√¢n t√≠ch chi ti·∫øt")
        
        if new_message:
            with st.spinner("ƒêang ph√¢n t√≠ch..."):
                analysis = st.session_state.ai_engine.analyze_message(new_message)
                
                st.metric("Ng·ªØ c·∫£nh", analysis.detected_context)
                st.metric("M·ª©c c·∫£m x√∫c", analysis.emotion_level)
                st.metric("ƒê·ªô kh·∫©n", f"{analysis.urgency*100:.0f}%")
                
                st.write("**T·ª´ kh√≥a ph√°t hi·ªán:**")
                for kw in analysis.keywords[:5]:
                    st.caption(f"‚Ä¢ {kw}")
                
                st.write("**Nhu c·∫ßu ·∫©n:**")
                for need in analysis.implied_needs:
                    st.caption(f"‚Ä¢ {need}")
        
        st.subheader("üìä Th·ªëng k√™")
        st.metric("S·ªë tin nh·∫Øn", len(st.session_state.conversation)//2)
        
        if st.session_state.conversation:
            contexts = [msg.get("context", "") for msg in st.session_state.conversation if msg["type"] == "sent"]
            if contexts:
                most_common = max(set(contexts), key=contexts.count)
                st.metric("Ng·ªØ c·∫£nh th∆∞·ªùng g·∫∑p", most_common)

# ==================== MAIN EXECUTION ====================

def main():
    """H√†m ch√≠nh ƒë·ªÉ ch·∫°y h·ªá th·ªëng"""
    print("üöÄ Kh·ªüi ƒë·ªông AI Nh·∫Øn Tin Tr∆∞·ªüng Th√†nh...")
    
    # 1. Kh·ªüi t·∫°o engine
    ai = MatureMessagingAI()
    
    # 2. Test v·ªõi tin nh·∫Øn m·∫´u
    test_messages = [
        "Anh ∆°i, em m·ªát qu√°",
        "D·∫°o n√†y anh c√≥ kh·ªèe kh√¥ng?",
        "Tr·ªùi l·∫°nh th·∫ø n√†y, nh·ªõ anh qu√°",
        "Anh c√≥ y√™u em kh√¥ng?",
        "...",
        "C√¥ng vi·ªác cƒÉng th·∫≥ng qu√°, em stress l·∫Øm"
    ]
    
    print("\nüß™ Test h·ªá th·ªëng:")
    for msg in test_messages:
        print(f"\nüì© Nh·∫≠n: {msg}")
        response = ai.auto_respond(msg)
        print(f"ü§ñ Tr·∫£ l·ªùi: {response['response_text']}")
        print(f"   ‚è± Delay: {response['delay_minutes']} ph√∫t")
        print(f"   üé≠ Ng·ªØ c·∫£nh: {response['context']}")
        print(f"   üí° Chi·∫øn l∆∞·ª£c: {response['strategy']}")
    
    print("\n‚úÖ H·ªá th·ªëng s·∫µn s√†ng!")
    print("\nüì± C√°c t√πy ch·ªçn ch·∫°y:")
    print("1. Web Interface: streamlit run mature_messaging_ai.py")
    print("2. Command Line: python mature_messaging_ai.py --test")
    print("3. Android Backend: S·ª≠ d·ª•ng class AndroidAutoMessaging")
    
    return ai

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--test", action="store_true", help="Ch·∫°y test")
    parser.add_argument("--web", action="store_true", help="Ch·∫°y web interface")
    args = parser.parse_args()
    
    if args.web:
        # Ch·∫°y web interface (c·∫ßn streamlit)
        create_web_interface()
    else:
        # Ch·∫°y test m·∫´u
        main()
